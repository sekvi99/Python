{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #Biblioteka służąca do obliczeń\n",
    "import math #funkcje matematyczne sqrt/ potęgi itd.\n",
    "import random #liczby pseudolosowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(arr):\n",
    "    max = 0\n",
    "    index = 0\n",
    "    for i in range(0,len(arr)):\n",
    "        if(arr[i]>max):\n",
    "            max = arr[i]\n",
    "            index = i\n",
    "        \n",
    "    arr[index] = 1\n",
    "\n",
    "    for i in range(0,len(arr)):\n",
    "        if(arr[i]<1):\n",
    "            arr[i]=0\n",
    "\n",
    "    return arr\n",
    "    \n",
    "class NeuralNetwork:\n",
    "    def __init__(self,sizes): \n",
    "        self.num_layers=len(sizes)\n",
    "        self.sizes=sizes\n",
    "        self.weights=[np.random.randn(x,y) for x,y in zip(sizes[:-1],sizes[1:])]\n",
    "        \n",
    "    def feedforward(self,sample):\n",
    "        #Wagi\n",
    "        for w in self.weights:\n",
    "            sample=activationFunction(np.dot(sample,w))\n",
    "        return sample    \n",
    "       \n",
    "    def resetWeights(self):\n",
    "        self.weights = [np.random.randn(x,y) for x,y in zip(sizes[:-1],sizes[1:])]\n",
    "    \n",
    "    def setWeights(self, weightsFromHeuristic): #pobierac wektor wag poprze heurystyke i wpisywac go do self.weights \n",
    "        for i in range(0, len(self.weights)):\n",
    "            for j in range(0, len(self.weights[i])):\n",
    "                for k in range(0, len(self.weights[i][j])):\n",
    "                    self.weights[i][j][k] = self.weights[i][j][k] * weightsFromHeuristic\n",
    "    \n",
    "    def error(self,sample):\n",
    "        processedSample = self.feedforward(sample[:4])\n",
    "       \n",
    "        if(sample[4:7] == [1,0,0]): \n",
    "            flowerList = [1,0,0]\n",
    "        elif(sample[4:7] == [0,1,0]):\n",
    "            flowerList = [0,1,0]\n",
    "        elif(sample[4:7] == [0,0,1]):\n",
    "            flowerList = [0,0,1]\n",
    "        \n",
    "        sum = 0\n",
    "        #Błąd średniokwadratowy\n",
    "        for i in range(0, len(processedSample)):\n",
    "            sum += (processedSample[i] - flowerList[i])**2\n",
    "        \n",
    "        #Zwrócenie errora dla pojedynczej probki\n",
    "        return sum\n",
    "        \n",
    "\n",
    "def activationFunction(x):\n",
    "    value = 1.0/(1.0+np.exp(-x))#sigmoid function\n",
    "    return value\n",
    "\n",
    "def globalErrorOfNN(weights,trainSet):\n",
    "    #stworzenie sieci neuronowej - obiekt sieci\n",
    "    errorWeight = []\n",
    "    netNetwork = NeuralNetwork([4,3,3])\n",
    "    \n",
    "    errors=[None] * len(trainSet)\n",
    "    \n",
    "    rand = random.randint(0, len(weights)-1)\n",
    "    weight = weights[rand]\n",
    "    \n",
    "    #ustawienie wag z weights do sieci dzieki setWeights()\n",
    "    netNetwork.setWeights(weight)\n",
    "    \n",
    "    #Obliczenie błędu dla pojedynczej próbki\n",
    "    i=0\n",
    "    for rekord in trainSet:\n",
    "        errors[i] = netNetwork.error(rekord)\n",
    "        i = i+1\n",
    "    #Błąd sieci\n",
    "    netError = sum(errors)/len(errors)\n",
    "    \n",
    "    #Dodanie wagi i  errora\n",
    "    errorWeight.append(netError)\n",
    "    errorWeight.append(weight)\n",
    "    #Średni error\n",
    "    return errorWeight\n",
    "\n",
    "def makeDecision(validationSet, best_Weight):\n",
    "    corrected = 0\n",
    "    net = NeuralNetwork([4,3,3])\n",
    "    net.setWeights(best_Weight)\n",
    "    answerSet = []\n",
    "    resaultSet = []\n",
    "    compareSet = []\n",
    "    \n",
    "    k=0\n",
    "    for k in range(0, len(validationSet)):\n",
    "        rekord = validationSet[k]\n",
    "        compareSet.append(rekord[4:7])\n",
    "        k = k +1\n",
    "        \n",
    "    \n",
    "    i = 0\n",
    "    for i in range(0, len(validationSet)):\n",
    "        rekord = validationSet[i]\n",
    "        answerSet.append(net.feedforward(rekord[:4]))\n",
    "        i = i + 1\n",
    "    \n",
    "    for rekord in answerSet:\n",
    "        resaultSet.append(function(rekord))\n",
    "        \n",
    "    corrected = 0\n",
    "    for z in range(0, len(compareSet)):\n",
    "        if((compareSet[z] == resaultSet[z]).all()):\n",
    "            corrected = corrected +1\n",
    "\n",
    "    accuracy = corrected/len(compareSet)*100\n",
    "    print(f'Skuteczność na poziomie: {accuracy} %'.format(accuracy))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Klasa cząstki\n",
    "class Particle:\n",
    "    def __init__(self, x0):\n",
    "        self.position = [] #pozycja cząstki\n",
    "        self.velocity = [] #prędkość cząstki\n",
    "        self.post_best = [] #najlepsza pozycja cząstki\n",
    "        self.err_best = -1 #najlepszy błąd cząstki\n",
    "        self.err = -1 #najlepszy błąd\n",
    "        \n",
    "        \n",
    "        for i in range(0, num_dimensions): #od 0 do ilości wymiarów\n",
    "            self.velocity.append(random.uniform(-1,1)) #losujemy wektor prędkości dla cząstki\n",
    "            self.position.append(x0[i]) #przypisujemy określoną pozycję dla cząstk\n",
    "    \n",
    "    #obliczamy obecny fitness dla konkretnej pozycji cząstki\n",
    "    def evaluate(self, costFunc):\n",
    "        self.err = costFunc(self.position)\n",
    "        \n",
    "        #sprawdzamy czy obecna pozycja jest najlepszą indywidualną pozycją\n",
    "        if self.err < self.err_best or self.err_best == -1: #jezeli jest rowny -1 to jeszcze nie ulegl zmianie\n",
    "            self.post_best = self.position #przypisanie nowej najlepszej pozycji\n",
    "            self.err_best = self.err #przypisanie nowego błędu\n",
    "    \n",
    "    #aktualizujemy prędkość cząstki\n",
    "    def update_velocity(self, post_best_g):\n",
    "        w = 0.5 #stala do mnożnika\n",
    "        c1 = 1 #1 składowa wektora prędkości\n",
    "        c2 = 2 #2 składowa wektora prędkości\n",
    "        \n",
    "        for i in range(0, num_dimensions):\n",
    "            r1 = random.random() #losowa wielkość dla pierwszej składowej wektora\n",
    "            r2 = random.random() #losowa wielkość dla 2 składowej wektora\n",
    "            \n",
    "            vel_cognitive=c1*r1*(self.post_best[i]-self.position[i]) #1 składowa\n",
    "            vel_social=c2*r2*(post_best_g[i]-self.position[i])       #2 składowa\n",
    "           \n",
    "            self.velocity[i]=w*self.velocity[i]+vel_cognitive+vel_social #zapamiętanie prędkości\n",
    "    \n",
    "    #aktualizujemy pozycje cząstki\n",
    "    def update_position(self, bounds):\n",
    "        for i in range(0, num_dimensions):\n",
    "            self.position[i] = self.position[i] + self.velocity[i] #przemieszczenie cząstki zgodne z wektorem jej aktualnej prędkości\n",
    "            \n",
    "            #jeżeli potrzebne to dodajemy maksymalną granicę\n",
    "            if self.position[i] > bounds[i][1]:\n",
    "                self.position[i] = bounds[i][1] #jeżeli przekroczyliśmy to ustawiamy na maksymalny zakres granic\n",
    " \n",
    "            #jeżeli potrzebnme to dodajemy minimalną granicę\n",
    "            if self.position[i] < bounds[i][0]:\n",
    "                self.position[i] = bounds[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(x):\n",
    "    #Błąd średniokwadratowy\n",
    "    total = 0 #koszt\n",
    "    for i in range(len(x)):\n",
    "        total+=x[i]**2\n",
    "    return total #zwracamy koszt\n",
    "\n",
    "#Klasa Algorytmu PSO (Particle swarm optimization - Algorytm roju cząstek)\n",
    "class PSO:\n",
    "    def __init__(self, costFunc, x0, bounds, num_particles, maxiter):\n",
    "        global num_dimensions\n",
    "        \n",
    "        num_dimensions = len(x0) #liczba rozmiarów jest równa długości ilości wymiarów przestrzeni\n",
    "        err_best_g = -1 #najlepszy error dla grupy\n",
    "        pos_best_g = [] #najlepsza pozycja dla grupy\n",
    "        self.weights_From_Heuristic = [] #wagi od heursytyki\n",
    "        \n",
    "        #zakładamy rój\n",
    "        swarm = []\n",
    "        for i in range(0, num_particles):\n",
    "            swarm.append(Particle(x0)) #tworzymy obiekt cząstki z klasy wyżej i dodajemy go do roju\n",
    "            \n",
    "        #Pętla optymalizacyjna\n",
    "        i = 0\n",
    "        while i < maxiter:\n",
    "            #Iterujemy przez cząstki i obliczamy dla nich funkcję fitness\n",
    "            for j in range(0,num_particles):\n",
    "                swarm[j].evaluate(costFunc) #obliczamy wartość funkcji dla j-tej cząstki w roju\n",
    "                \n",
    "                \n",
    "                #Sprawdzamy czy obecna cząstka jest najlepszą cząstka globalną\n",
    "                if swarm[j].err < err_best_g or err_best_g == -1: \n",
    "                    pos_best_g = list(swarm[j].position) #zwraca listę w tym wypadku zawierająca wsp pozycji j-tej cząstki w roju\n",
    "                    err_best_g = float(swarm[j].err)\n",
    "                    self.weights_From_Heuristic.append(err_best_g)\n",
    "                \n",
    "            \n",
    "            #Iterujemy przez rój i aktualizyjemy pozycje oraz ich wektory prędkości\n",
    "            for j in range(0, num_particles):\n",
    "                swarm[j].update_velocity(pos_best_g) #aktualizujemy prędkość\n",
    "                swarm[j].update_position(bounds) #aktualizyjemy pozycję\n",
    "            \n",
    "            i+=1\n",
    "            \n",
    "            \n",
    "            \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataBaseCsv():\n",
    "    dane = []\n",
    "    f = open(\"iris.csv\", \"r\")\n",
    "    for line in f:\n",
    "        dane.append([float(s) for s in line.split(\",\")])\n",
    "    random.shuffle(dane)\n",
    "    return dane\n",
    "\n",
    "def split(base):\n",
    "    brd = math.ceil(.7*len(base))\n",
    "    train = base[:brd]\n",
    "    val = base[brd:]\n",
    "    return train,val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obsluga heurystyki, w celu pozyskania wag\n",
    "initial = [10,10]\n",
    "weights = []\n",
    "bounds=[(-10,10), (-10,10)]\n",
    "#Podajemy funkcję do optymalizacji, początkowe współrzędne, granice przestrzeni, liczbę cząstek oraz ilość iteracji\n",
    "weights = PSO(cost_function, initial, bounds, num_particles=15, maxiter=30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Obsługa bazy danych\n",
    "base = readDataBaseCsv()\n",
    "sums = [None] * len(baza)\n",
    "sizes = [4,3,3]\n",
    "net = NeuralNetwork(sizes)\n",
    "trainBase, validationBase = split(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6291933248991084\n",
      "4.0749066840463675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-424-8a276610f5f3>:58: RuntimeWarning: overflow encountered in exp\n",
      "  value = 1.0/(1.0+np.exp(-x))#sigmoid function\n"
     ]
    }
   ],
   "source": [
    "#Szukanie najmniejszego błedu w bazie treningowej\n",
    "i = 0\n",
    "res = []\n",
    "for elem in trainBase:\n",
    "    net.resetWeights()\n",
    "    res.append(globalErrorOfNN(weights.weights_From_Heuristic, trainBase))\n",
    "    i = i +1\n",
    "\n",
    "#Znalezienie indexu i minimalnego błędu\n",
    "min_error = 200\n",
    "weight = 0\n",
    "for i in range(0, len(res)):\n",
    "    if min_error > res[i][0]:\n",
    "        min_error = res[i][0]\n",
    "        weight = res[i][1]\n",
    "\n",
    "print(min_error)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skuteczność na poziomie: 53.333333333333336 %\n"
     ]
    }
   ],
   "source": [
    "makeDecision(validationBase, weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
